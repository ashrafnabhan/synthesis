<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Systematic reviews of clinical tests – An Introduction to Evidence Synthesis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./summary.html" rel="next">
<link href="./interventions.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./tests.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Systematic reviews of clinical tests</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">An Introduction to Evidence Synthesis</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interventions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Systematic reviews of healthcare interventions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tests.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Systematic reviews of clinical tests</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#diagnostic-tests" id="toc-diagnostic-tests" class="nav-link active" data-scroll-target="#diagnostic-tests"><span class="header-section-number">3.1</span> Diagnostic tests</a>
  <ul class="collapse">
  <li><a href="#the-review-question" id="toc-the-review-question" class="nav-link" data-scroll-target="#the-review-question"><span class="header-section-number">3.1.1</span> The review question</a></li>
  <li><a href="#identifying-research-evidence" id="toc-identifying-research-evidence" class="nav-link" data-scroll-target="#identifying-research-evidence"><span class="header-section-number">3.1.2</span> Identifying research evidence</a></li>
  <li><a href="#data-extraction" id="toc-data-extraction" class="nav-link" data-scroll-target="#data-extraction"><span class="header-section-number">3.1.3</span> Data extraction</a></li>
  <li><a href="#risk-of-bias-assessment" id="toc-risk-of-bias-assessment" class="nav-link" data-scroll-target="#risk-of-bias-assessment"><span class="header-section-number">3.1.4</span> Risk of bias assessment</a></li>
  <li><a href="#synthesis" id="toc-synthesis" class="nav-link" data-scroll-target="#synthesis"><span class="header-section-number">3.1.5</span> Synthesis</a></li>
  <li><a href="#presentation-of-results" id="toc-presentation-of-results" class="nav-link" data-scroll-target="#presentation-of-results"><span class="header-section-number">3.1.6</span> Presentation of results</a></li>
  </ul></li>
  <li><a href="#prognostic-tests" id="toc-prognostic-tests" class="nav-link" data-scroll-target="#prognostic-tests"><span class="header-section-number">3.2</span> Prognostic tests</a>
  <ul class="collapse">
  <li><a href="#defining-the-review-question-setting-inclusion-criteria" id="toc-defining-the-review-question-setting-inclusion-criteria" class="nav-link" data-scroll-target="#defining-the-review-question-setting-inclusion-criteria"><span class="header-section-number">3.2.1</span> Defining the review question: setting inclusion criteria</a></li>
  <li><a href="#defining-the-review-question-other-considerations" id="toc-defining-the-review-question-other-considerations" class="nav-link" data-scroll-target="#defining-the-review-question-other-considerations"><span class="header-section-number">3.2.2</span> Defining the review question: other considerations</a></li>
  <li><a href="#identifying-research-evidence-1" id="toc-identifying-research-evidence-1" class="nav-link" data-scroll-target="#identifying-research-evidence-1"><span class="header-section-number">3.2.3</span> Identifying research evidence</a></li>
  <li><a href="#data-extraction-1" id="toc-data-extraction-1" class="nav-link" data-scroll-target="#data-extraction-1"><span class="header-section-number">3.2.4</span> Data extraction</a></li>
  <li><a href="#risk-of-bias-assessment-1" id="toc-risk-of-bias-assessment-1" class="nav-link" data-scroll-target="#risk-of-bias-assessment-1"><span class="header-section-number">3.2.5</span> Risk of bias assessment</a></li>
  <li><a href="#synthesis-1" id="toc-synthesis-1" class="nav-link" data-scroll-target="#synthesis-1"><span class="header-section-number">3.2.6</span> Synthesis</a></li>
  <li><a href="#systematic-review-as-a-driver-for-improved-study-quality" id="toc-systematic-review-as-a-driver-for-improved-study-quality" class="nav-link" data-scroll-target="#systematic-review-as-a-driver-for-improved-study-quality"><span class="header-section-number">3.2.7</span> Systematic review as a driver for improved study quality</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Systematic reviews of clinical tests</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Clinical tests are routinely used for diagnosis, confirming or excluding the presence of a disease or condition (such as pregnancy). They are also used to monitor disease progression, assess prognosis, and screen asymptomatic populations for disease. Any process that yields information used to inform patient management can be regarded as a clinical test.1 This includes a wide range of processes from history taking and physical examination to complex imaging techniques. The test itself is an intervention and forms part of the continuum of patient care. New tests are adopted into clinical practice for a number of reasons, including replacement of an existing test (where the new test is expected to reduce the negative impact on the patient, provide better information, or equivalent information for less cost), triage (to decide whether a more expensive or invasive test is necessary), or as an addition to the existing testing protocol.</p>
<p>The ultimate aim of any research on clinical tests should be to determine impact upon patient management and outcome. An RCT comparing the effect of different diagnostic strategies on one or more clinical outcomes could be considered ideal, as it provides direct information on the benefit to patients and can be modified to address various types of diagnostic question.2 However, RCTs may not be appropriate for addressing all diagnostic questions3, 4 and to date much of the research on diagnostic tests is in the form of test accuracy studies. The basic aim of test accuracy studies is to assess how well a test can distinguish between people with and without the disease/condition of interest. The outcome measures used describe the probabilistic relationships between positive and negative test results, and the presence or absence of disease, as compared with the best currently available method (i.e.&nbsp;the clinical reference standard). As such, test accuracy studies do not directly measure the relative benefits and harms to patients of testing. Evidence on the accuracy of a test, combined with evidence of a prognostic link between the target condition and preventable morbidity/mortality, may be considered indicative of the likely effectiveness of the test.5 Where a new test is being evaluated, evidence for a prognostic link between the target disease/condition and long-term morbidity or mortality should be available as should an effective intervention. However, this is not always the case as tests can be established in clinical practice with limited supporting evidence.</p>
<p>When considering a systematic review of test accuracy studies, it is important to assess whether review findings will be able to provide the information necessary to inform clinical practice. Any review of test accuracy is likely to be of limited value where evidence is lacking that the disease/condition is associated with long-term morbidity or mortality, or where no effective intervention is available. This is illustrated by the following examples:</p>
<ul>
<li><p>Magnetic Resonance Angiography (MRA) versus intra-arterial Digital Subtraction Angiography (DSA) for the detection of carotid artery stenosis.6 There is evidence from RCTs that carotid endarterectomy is an effective treatment for symptomatic carotid artery stenosis at thresholds defined by DSA. MRA is a less invasive test option. A review of test accuracy is therefore likely to be informative.</p></li>
<li><p>Ultrasound versus Micturating Cystourethrography (MCUG) for the detection of vesicoureteric reflux (VUR) in children with urinary tract infection (UTI).7 There is conflicting evidence of a link between VUR and long-term renal damage and the effectiveness of treatment options, such as prophylactic antibiotics, is also uncertain. A review of test accuracy alone is therefore unlikely to be informative.</p></li>
</ul>
<p>Although some study designs, such as those based upon multivariable prediction modelling, may better reflect the true nature of the diagnostic workup and are potentially more informative than test accuracy studies,8, 9 they are rare. Consequently, systematic review methods for assessing clinical tests have largely focused upon test accuracy studies and this chapter discusses methods developed specifically to deal with such studies. Section 2.2 focuses on diagnostic accuracy studies, but the methods described also apply to test accuracy studies used to assess the performance of new screening tests, within established screening programmes. The clinical effectiveness</p>
<p>of screening programmes is best evaluated using RCTs and systematic reviews of such studies should follow the principles outlined in Chapter 1. Section 2.3 describes methods for reviewing prognostic studies.</p>
<p>In light of the limitations described in relation to test accuracy studies, careful consideration should always be given to the likely informative value and any additional data requirements before undertaking a systematic review of test accuracy.</p>
<section id="diagnostic-tests" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="diagnostic-tests"><span class="header-section-number">3.1</span> Diagnostic tests</h2>
<section id="the-review-question" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="the-review-question"><span class="header-section-number">3.1.1</span> The review question</h3>
<p>As with all systematic reviews, the development of a clear, well-defined question is essential to maintaining transparency of the review process and to the quality and relevance of the findings. Some aspects of the question require consideration when planning a review of test accuracy.</p>
<section id="population" class="level4" data-number="3.1.1.1">
<h4 data-number="3.1.1.1" class="anchored" data-anchor-id="population"><span class="header-section-number">3.1.1.1</span> Population</h4>
<p>Diagnostic tests perform differently in different populations,10, 11 for example it would generally be inappropriate to evaluate the performance of a test in a secondary care population when the test is mainly used in primary care. Both frequency and severity of the target condition would be expected to be greater in secondary care. It is therefore important to clearly define the population of interest. The ideal study sample for a test accuracy study is a consecutive or randomly selected series of patients in whom the target condition is suspected, or for screening studies, the target population. Because participant sampling methods are often poorly reported in test accuracy studies,12 using the sampling method as an inclusion/exclusion criterion is likely to result in a substantial reduction in available data. It is likely to be more useful to consider the sampling method and/or its reporting as an aspect of study quality (see Section 2.2.5 Quality assessment) and to base the inclusion criteria relating to the population upon participant characteristics. For example in a review comparing the accuracy of different imaging techniques, the inclusion criteria might state that only patients with a specified level of symptoms, representative of those in whom the test would be used for intervention planning, are eligible.</p>
</section>
<section id="intervention-index-test" class="level4" data-number="3.1.1.2">
<h4 data-number="3.1.1.2" class="anchored" data-anchor-id="intervention-index-test"><span class="header-section-number">3.1.1.2</span> Intervention (index test)</h4>
<p>In reviews of test accuracy the ‘index test’ (the test whose performance is being evaluated) can be viewed as the intervention. As with any review, the scope of the question can be broad such as ’what is the optimum testing pathway for the diagnosis and follow-up investigation of childhood urinary tract infection (UTI)?’13 or it can be narrow; for example ’what is the diagnostic accuracy of magnetic resonance angiography (MRA) when compared with intra-arterial x-ray angiography, for the detection of carotid artery stenosis?’6 The former is likely to include a number of different technologies, addressing multiple target conditions, whereas the latter compares the performance of an alternative (replacement), less invasive or less costly diagnostic technology with that of the reference standard for the detection of a specified target condition. The rate of technological development may be an important consideration; in this latter example inclusion of MRA techniques that are already obsolete in clinical practice, is unlikely to be useful.</p>
<p>Careful consideration should always be given to the equivalence of different analytical techniques when setting inclusion criteria. For example, a systematic review of faecal occult blood tests to screen for colorectal cancer14, 15 evaluated both immunochemical and colourimetric methods for detecting blood in the faeces; though both methods target blood, they cannot be considered equivalent tests.</p>
<p>The traditional concept of test accuracy often implies the dichotomisation of data into test results which are classified as positive (target condition present) or negative (target condition absent). Any systematic review of test accuracy will therefore need to consider diagnostic thresholds (points at which results are classified as positive or negative) for each included index test.</p>
</section>
<section id="reference-standardcomparator" class="level4" data-number="3.1.1.3">
<h4 data-number="3.1.1.3" class="anchored" data-anchor-id="reference-standardcomparator"><span class="header-section-number">3.1.1.3</span> Reference standard/comparator</h4>
<p>The reference standard is usually the best test currently available, and is the standard against which the index test is compared. It need not be the test used routinely in practice (although it can be), and may include information which is not known for some time after the tests have been done (e.g.&nbsp;follow-up of test negatives in cancer).</p>
<p>The test accuracy study is based upon a one-sided comparison between the results of the index test and those of the reference standard. Any discrepancy is assumed to arise from error in the index test. Selection of the reference standard is therefore critical to the validity of a test accuracy study and the definition of the diagnostic threshold forms part of that reference standard.</p>
<p>It is important to note that the assumption of 100% accuracy for the reference standard rarely holds true in practice. This represents a fundamental flaw in the test accuracy study design, since the index test can never be deemed to perform better than the reference standard, and its value may therefore be underestimated.16</p>
<p>Where several tests are available to diagnose the target condition, there is often no consensus about which test constitutes the reference standard. In such cases a</p>
<p>composite reference standard, which combines the results of several available tests to produce a better indicator of true disease status may be used.17 A number of statistical methods have been proposed to estimate the performance of tests in the absence of a single accepted reference standard.18, 19</p>
<p>There may be instances when it is deemed unethical to use an invasive procedure as a reference standard in a study.20 In such cases, clinical follow-up and final diagnosis</p>
<p>may sometimes be used as a surrogate reference standard. There will also be occasions when clinical follow-up and final diagnosis provides the most appropriate reference standard. The length of follow-up should ideally be defined in advance. Studies using follow-up and clinical outcome in this way may be viewed as prognostic studies in that they are measuring the accuracy with which the test is able to predict a future event, rather than the accuracy with which it is able to determine current status. Where such studies are included in a systematic review, it is important to define, in advance, what constitutes appropriate follow-up and hence an adequate reference standard.</p>
<p>The comparator is an alternative test, usually that which is used in current practice, against which the index test must be evaluated in order to assess its potential role. Ideally, this should be done by comparing index test and comparator to the reference standard in the same population.</p>
</section>
<section id="outcome-measures" class="level4" data-number="3.1.1.4">
<h4 data-number="3.1.1.4" class="anchored" data-anchor-id="outcome-measures"><span class="header-section-number">3.1.1.4</span> Outcome measures</h4>
<p>The primary outcome of interest for any systematic review of test accuracy is the data required to populate 2 x 2 contingency tables. These describe the relationship between the results of the index test and the reference standard at a given diagnostic threshold (point at which results are classified as positive or negative). The table includes the number of true positives (TP: those that have the disease and test positive), false positives (FP: those that do not have the disease and test positive), false negatives (FN: those that do have the disease and test negative) and true negatives (TN: those that do not have the disease and test negative).</p>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 26%">
<col style="width: 28%">
<col style="width: 21%">
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>Reference standard</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>Disease</td>
<td>No disease</td>
</tr>
<tr class="odd">
<td>Index test</td>
<td>Positive</td>
<td>TP</td>
<td>FP</td>
</tr>
<tr class="even">
<td></td>
<td>Negative</td>
<td>FN</td>
<td>TN</td>
</tr>
</tbody>
</table>
<p>From the 2 x 2 contingency table, the following commonly used measures of test performance can be calculated:</p>
<p>Sensitivity =vThe proportion of people with the target condition who have a positive test result.</p>
<p>Specificity =vThe proportion of people without the target condition who have a negative test result.</p>
<p>Overall accuracy =vThe proportion of people correctly classified by the test.</p>
<p>Positive predictive value =vThe probability of disease among persons with a positive test result.</p>
<p>Negative predictive value =vThe probability of non-disease among persons with a negative test result.</p>
<p>Positive likelihood ratio and Negative likelihood ratio.</p>
<p>Likelihood ratios (LR) describe how many times more likely it is that a person with the target condition will receive a particular test result than a person without. Positive likelihood ratios greater than 10 or negative likelihood ratios less than 0.1 are sometimes judged to provide convincing diagnostic evidence.21</p>
<p>Diagnostic odds ratio = Used as an overall indicator of diagnostic performance and calculated as the odds of a positive test result among those with the target condition, divided by the odds of a positive test result among those without the condition.</p>
<p>In primary studies, a receiver operating characteristic (ROC) curve describes the relationship between ‘true positive fraction’ (sensitivity) and ‘false positive fraction’ (1– specificity) for different positivity thresholds. It is used to display the trade-offs between sensitivity and specificity as a result of varying the diagnostic threshold.</p>
<p>Below is an example ROC analysis for serum thyroid stimulating hormone (TSH) as a diagnostic test for primary hypothyroidism:</p>
<p>Test results (Serum TSH) vs.&nbsp;reference standard (thyroid status)</p>
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 38%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Serum TSH (mIU/L)</th>
<th style="text-align: center;"><blockquote class="blockquote">
<p>Number with primary hypothyroidism</p>
</blockquote></th>
<th><blockquote class="blockquote">
<p>Number without primary hypothyroidism</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt;6</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>17</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>325</p>
</blockquote></td>
</tr>
<tr class="even">
<td>6-12</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>42</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>158</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>13-15</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>46</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>48</p>
</blockquote></td>
</tr>
<tr class="even">
<td>16-20</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>66</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>33</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>&gt;20</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>284</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>5</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p>2 x 2 contingency data for serum TSH diagnostic threshold (derived by summing the numbers of participants, with and without primary hypothyroidism, on either side of the diagnostic threshold)</p>
</blockquote>
<table class="caption-top table">
<colgroup>
<col style="width: 62%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th>Diagnostic threshold for a positive test result (mIU/L)</th>
<th style="text-align: center;"><blockquote class="blockquote">
<p>TP</p>
</blockquote></th>
<th style="text-align: center;"><blockquote class="blockquote">
<p>FP</p>
</blockquote></th>
<th style="text-align: center;"><blockquote class="blockquote">
<p>FN</p>
</blockquote></th>
<th style="text-align: center;"><blockquote class="blockquote">
<p>TN</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>≥6</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>438</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>244</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>17</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>325</p>
</blockquote></td>
</tr>
<tr class="even">
<td>&gt;12</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>396</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>86</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>59</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>483</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>&gt;15</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>350</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>38</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>105</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>531</p>
</blockquote></td>
</tr>
<tr class="even">
<td>&gt;20</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>284</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>5</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>171</p>
</blockquote></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>564</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p>Sensitivity and specificity values for each diagnostic threshold (derived from the 2 x 2 contingency data and expressed as percentages)</p>
</blockquote>
<table class="caption-top table">
<colgroup>
<col style="width: 65%">
<col style="width: 15%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th>Diagnostic threshold for a positive test result (mIU/L)</th>
<th style="text-align: center;">Sensitivity</th>
<th style="text-align: center;"><blockquote class="blockquote">
<p>Specificity</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>≥6</td>
<td style="text-align: center;">96.2%</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>57.1%</p>
</blockquote></td>
</tr>
<tr class="even">
<td>&gt;12</td>
<td style="text-align: center;">87.0%</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>84.9%</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>&gt;15</td>
<td style="text-align: center;">76.9%</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>93.3%</p>
</blockquote></td>
</tr>
<tr class="even">
<td>&gt;20</td>
<td style="text-align: center;">62.4%</td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>99.1%</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p>‘Q*’, or maximal joint sensitivity and specificity, is the point on the ROC curve that intersects with the line of symmetry. It is sometimes used as an indicator of overall test performance where there is no clinical preference for maximising either sensitivity (minimizing false negatives) or specificity (minimizing false positives). However Q* is not useful if the thresholds at which tests have been evaluated do not lie close to the line of symmetry and can then give misleading results if used to compare performance between tests.</p>
<p>In some scenarios (e.g.&nbsp;tests used in population screening) a threshold which skews diagnostic performance may be preferable (e.g.&nbsp;minimizing the number of false negatives at the expense of some increase in the number of false positive results, in conditions/diseases where missing the presence of disease will lead to serious consequences). Overall diagnostic accuracy is summarised by the area under the curve (AUC); the closer the curve is to the upper left hand corner the better the diagnostic performance.22 The AUC ranges from 0 to 1, with 0.5 indicating a poor test where the accuracy is equivalent to chance.</p>
<p>As with other types of intervention, when assessing the clinical effectiveness of a diagnostic test, it is important to consider all outcome measures which may be relevant to the use of the test in practice. These might include adverse events (see Chapter 4) and the preferences of patients, although inclusion of such information is rare.</p>
<section id="study-design" class="level6" data-number="3.1.1.4.0.1">
<h6 data-number="3.1.1.4.0.1" class="anchored" data-anchor-id="study-design"><span class="header-section-number">3.1.1.4.0.1</span> Study design</h6>
<p>There are two basic types of test accuracy study: ‘single-gate’ which are similar to consecutive series (and previously sometimes called diagnostic cohort studies) and ‘two-gate’ which are similar to case-control studies. The term ‘two-gate’ being used</p>
<p>where two sets of inclusion criteria or ‘gates’ are applied, one for participants who have the target condition and one for those who do not. These designs differ in structure from other cohort and case-control studies in that both are generally cross-sectional in nature.23</p>
<ul>
<li><p>The single-gate design includes participants in whom the disease status is unknown, and compares the results of the index test with those of the reference standard used to confirm diagnosis, i.e.&nbsp;it is broadly representative of the scenario in which the test would be used in practice.</p></li>
<li><p>The two-gate design compares the results of the index test in patients with an established diagnosis of the target condition with its results in healthy controls or controls with another diagnosis (known status, with respect to the target condition, is therefore treated as the reference standard); i.e.&nbsp;it is</p></li>
</ul>
<blockquote class="blockquote">
<p>unrepresentative of practice and is unlikely to contain the full spectrum of health and disease over which the test would be used.</p>
</blockquote>
<p>There are inherent problems with the two-gate design that may lead to bias. The selective inclusion of cases with more advanced disease is likely to lead to over estimations of sensitivity and inclusion of healthy controls is likely to lead to over estimations of specificity. The recruitment of healthy controls from the general population has been associated with two- to three-fold increases in measures of test performance time-to-events derived from a diagnostic cohort design.11, 24, 25 This over estimation can be increased further when cases of severe disease are used alongside healthy controls.26 By contrast, where cases are derived from individuals with mild disease, underestimations of sensitivity can result.27 Where the control group is derived from patients with alternative diagnoses, specificity may be under or overestimated, depending upon the alternative diagnosis.23 In theory, the two-gate study design could produce a valid estimate of test performance if the cases were sampled to match the reference standard positive patients in a single-gate study (in terms of the spectrum of disease severity) and controls were matched to the reference standard negative patients (in terms of the spectrum of alternative conditions). In practice however, this is difficult to achieve.23 Whilst two-gate studies are therefore of limited use in assessing how a test is likely to perform in clinical practice, they can be useful in the earlier phases of test development.28</p>
<p>Where systematic reviews include both single and two-gate study designs, careful consideration should be given to the methods of analysis and the impact of study design should be assessed in any meta-analyses.29</p>
</section>
</section>
</section>
<section id="identifying-research-evidence" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="identifying-research-evidence"><span class="header-section-number">3.1.2</span> Identifying research evidence</h3>
<section id="sources" class="level4" data-number="3.1.2.1">
<h4 data-number="3.1.2.1" class="anchored" data-anchor-id="sources"><span class="header-section-number">3.1.2.1</span> Sources</h4>
<p>The importance of searching a wide range of databases to avoid missing relevant diagnostic test accuracy studies has been demonstrated, with MEDLINE, EMBASE, BIOSIS, LILACS, Pascal and Science Citation Index all providing unique records.30 The reference lists of included studies can also be a useful resource.</p>
<p>The Cochrane Diagnostic Test Accuracy Working Group31 is creating a database of test accuracy studies,32 similar to the non-topic specific Cochrane Central Register of Controlled Trials (CENTRAL) which includes details of published articles taken from bibliographic databases and other published and unpublished sources.33</p>
</section>
<section id="database-searching" class="level4" data-number="3.1.2.2">
<h4 data-number="3.1.2.2" class="anchored" data-anchor-id="database-searching"><span class="header-section-number">3.1.2.2</span> Database searching</h4>
<p>Many electronic databases do not have appropriate indexing terms to label test accuracy studies, and those that do tend not to apply them consistently.30, 34-36 They also vary in their design which adds to the difficulty in identification.34 The problem is compounded by the fact that the original authors are often poor at identifying their studies as being test accuracy.30</p>
<p>It has been reported that the use of filters to identify reports of diagnostic test accuracy studies in electronic databases may miss a considerable number of relevant articles and is therefore not generally considered appropriate.34, 36, 37 Database searching should concentrate on terms for index tests and target conditions. If further restriction is required, it can be achieved by means of topic specific terms, rather than using a filter.36, 38 It is hoped, however, that in time, as the issues of reporting and indexing diagnostic, screening and prognostic studies are more widely realised, the situation will improve allowing the development of more accurate filters.</p>
</section>
<section id="publication-bias" class="level4" data-number="3.1.2.3">
<h4 data-number="3.1.2.3" class="anchored" data-anchor-id="publication-bias"><span class="header-section-number">3.1.2.3</span> Publication bias</h4>
<p>As the data used in studies of test accuracy are often collected as part of routine clinical practice (and in the past have tended not to require formal registration) it has been argued that test accuracy studies are more easily conducted and abandoned than RCTs. They may therefore be particularly susceptible to publication bias.39 Simulation studies have, however, indicated that the effect of publication bias on meta-analytic estimates of the Diagnostic Odds Ratio (DOR) is not likely to be large.40</p>
<p>It has been demonstrated that the unique features of the test accuracy study make the application of the Begg, Egger, and Macaskill tests of funnel plot asymmetry potentially misleading.40 An alternative approach uses funnel plots of (natural logarithm (ln) DOR) vs.&nbsp;(1/√effective sample size) and tests for asymmetry using related regression or rank correlation tests.40 It should be noted that the power of all statistical tests for funnel plot asymmetry decreases with increasing heterogeneity of DOR. It should also be noted that factors other than publication bias, for example aspects of study quality and population characteristics, may be associated with sample size.</p>
<p>Given the limitations of current knowledge, to ignore the possibility of publication bias would seem unwise, however, its assessment in reviews of test accuracy is complex.</p>
</section>
</section>
<section id="data-extraction" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="data-extraction"><span class="header-section-number">3.1.3</span> Data extraction</h3>
<p>The same precautions against reviewer bias and error should be employed whilst extracting data from test accuracy studies as would be applied in any other type of review. Independent checking of 2x2 data is particularly important, as test accuracy studies are often poorly reported,12, 41 and the production of a 2x2 table from these studies can be far from straightforward.</p>
<p>Some studies may provide the actual results for each test for individual patients. In this case the researcher may need to classify each patient according to the diagnostic thresholds defined in the review protocol.</p>
<p>Studies may provide categorical data, which may represent multiple categories or stages of disease. In this case data will need to be extracted for the numbers of index test positive and negative participants (using the threshold(s) defined in the review protocol, which may include all thresholds reported) with and without the target condition (as defined by the reference standard, using the threshold(s) defined in the review protocol).</p>
<p>There may be instances when the raw data are not reported, but 2x2 data can be calculated from reported accuracy measures and total numbers of diseased or non- diseased patients.</p>
<p>Somewhat more problematic are cases when the data do not ‘fit’ the 2x2 contingency table model. ‘Forcing’ data into a 2x2 contingency table, for example by classifying uncertain index test results as FP or FN, may be inappropriate. The contingency table can be extended to form a six cell table, which accommodates uncertain or indeterminate index test results.</p>
<p>The informative value of an indeterminate test result can be assessed using an indeterminate likelihood ratio (or LR+/-), defined as the probability of an indeterminate test result in the presence of disease divided by the probability of an indeterminate test result in the absence of disease.</p>
<p>When index test and reference standard give clear results (ie considered determinate), but there is incomplete concordance, the 2x2 table may be expanded to accommodate a more complete clinical picture.</p>
</section>
<section id="risk-of-bias-assessment" class="level3" data-number="3.1.4">
<h3 data-number="3.1.4" class="anchored" data-anchor-id="risk-of-bias-assessment"><span class="header-section-number">3.1.4</span> Risk of bias assessment</h3>
<p>Structured appraisal of methodological quality is key to assessing the reliability of test accuracy studies included in a systematic review.44 Quality assessment should consider the association of individual elements of methodological quality with test accuracy; generating overall ‘quality scores’ is not recommended.45</p>
<p>There are many differences in the design and conduct of diagnostic accuracy studies that can affect the interpretation of their results. Some differences lead to systematic bias such that estimates of diagnostic performance will differ from their true values,</p>
<p>others give rise to variation in results between studies, which can limit applicability. The distinction between bias and variation is not always clear, and quality assessment checklists have tended to include items that are pertinent to both.46, 47 Sources of</p>
<p>variation and bias that are potentially relevant when considering studies of test accuracy are described in Table 2.1. Whilst it is clear that variation (e.g.&nbsp;in the demographic characteristics or severity of disease in the study population) can affect the applicability of the results of both individual studies and systematic reviews, there is limited evidence on the effects of design-related biases in primary studies on the results of systematic reviews.11, 24, 26, 48 Research on the impact of design-related biases is largely a work in progress, being dependent upon the availability of adequate data sets and consistent methods of quality assessment.</p>
<p>Guidelines for assessing the methodological quality of test accuracy studies were first developed in the 1980s.16, 46 A large number of quality assessment tools and checklists have since been published, often as part of individual systematic reviews. Methodological work has identified 67 tools designed to assess the quality of test accuracy studies and 24 guides to the interpretation, conduct or reporting of test</p>
<p>accuracy studies.49 Only six of the quality assessment tools specified which aspects of quality they aimed to cover.50-55 One quality assessment tool46 and one guide to the reporting of diagnostic accuracy studies56 provided detailed information of how items had been selected for inclusion in the tool, and none reported systematic evaluation of the tool.</p>
<p>QUADAS was the first attempt to develop an evidence-based, validated, quality assessment tool specifically for use in systematic reviews of test accuracy studies.47 The items included in QUADAS were derived by combining empirical evidence from three systematic reviews, reported in two publications11, 49 with expert opinion, using a formal consensus method.47 The QUADAS criteria and the sources of bias and variation</p>
<p>to which they relate are given in Table 2.2. Each item is scored as ‘Yes’, ‘No’ or ‘Unclear’ and generic guidance on scoring has been published.47, 57 It is, however, impossible</p>
<p>to provide a universally applicable description of how some QUADAS items should be scored, e.g.&nbsp;the definition of ‘an appropriate patient spectrum’, or ‘a reference standard likely to correctly classify the target condition.’ It is therefore important that guidance on scoring be refined for individual reviews, with the definition of what should be scored as ‘Yes’, ‘No’ and ‘Unclear’ being specified for each QUADAS item and agreed by the whole review team at the start of the review; this should be done in close consultation with clinical experts.57 Piloting of the quality assessment process on a small sample</p>
<p>of included studies should be done in an attempt to eliminate any discrepancies in understanding between reviewers.</p>
<p>Table 2.1: Sources of bias and variation in test accuracy studies11</p>
<p>Population</p>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 6%">
<col style="width: 82%">
</colgroup>
<thead>
<tr class="header">
<th>Demographic characteristics</th>
<th><blockquote class="blockquote">
<p>Variation</p>
</blockquote></th>
<th><blockquote class="blockquote">
<p>Test may perform differently in different populations.</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Disease severity</td>
<td><blockquote class="blockquote">
<p>Variation</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>Differences in disease severity may lead to different estimates of diagnostic performance.</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Disease prevalence</td>
<td><blockquote class="blockquote">
<p>Variation Bias</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>The prevalence of the target condition varies with the setting and may affect estimates of diagnostic performance. In settings of higher prevalence, interpreters are more prone to classify test results as abnormal (context bias).</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Participant selection</td>
<td><blockquote class="blockquote">
<p>Variation</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>A selection process that may not include a spectrum of patients similar to that in which the test will be used in practice may limit the applicability of study findings.</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p>Test methods</p>
<table class="caption-top table">
<colgroup>
<col style="width: 8%">
<col style="width: 10%">
<col style="width: 80%">
</colgroup>
<thead>
<tr class="header">
<th>Test execution</th>
<th><blockquote class="blockquote">
<p>Variation</p>
</blockquote></th>
<th><blockquote class="blockquote">
<p>Differences in the execution of the index test and/or reference standard can result in different estimates of diagnostic performance; clear reporting of the methods used is therefore important.</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Technological</td>
<td><blockquote class="blockquote">
<p>Variation development</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>Diagnostic performance of tests can change over time due to technological improvements.</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Treatment paradox</td>
<td><blockquote class="blockquote">
<p>Bias</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>Occurs when treatment is started, based upon the results of one test prior to undertaking the other; thus disease state is potentially altered between tests.</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Disease progression</td>
<td><blockquote class="blockquote">
<p>Bias</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>Occurs when there is sufficient time delay between the application of the index test and the reference standard to allow change in the disease state.</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p>Application of the reference standard</p>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 6%">
<col style="width: 70%">
</colgroup>
<thead>
<tr class="header">
<th>Use of an inappropriate reference standard</th>
<th><blockquote class="blockquote">
<p>Bias</p>
</blockquote></th>
<th><blockquote class="blockquote">
<p>The error in diagnoses derived from an imperfect reference standard can result in underestimation of the performance of the index test.</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Differential verification</td>
<td><blockquote class="blockquote">
<p>Bias</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>Occurs when the diagnosis is verified using different reference standards, depending upon the result of the index test.</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Partial verification</td>
<td><blockquote class="blockquote">
<p>Bias</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>Occurs where only a selected sample of participants undergoing the index test also receive the reference standard.</p>
</blockquote></td>
</tr>
</tbody>
</table>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 3%">
<col style="width: 90%">
</colgroup>
<thead>
<tr class="header">
<th>Test or diagnostic review</th>
<th><blockquote class="blockquote">
<p>Bias</p>
</blockquote></th>
<th><blockquote class="blockquote">
<p>Where interpretation of either the index test or reference standard may be influenced by knowledge of the results of the other test. Diagnostic review bias may be present when the results of the index test are known to those interpreting the reference standard. Test review bias may be present when the results of the reference standard are known to those interpreting the index test.</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Clinical review</td>
<td><blockquote class="blockquote">
<p>Bias</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>The availability of other relevant clinical information (e.g.&nbsp;symptoms, co-morbidities) may also affect estimates of test performance.</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Incorporation</td>
<td><blockquote class="blockquote">
<p>Bias</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>Occurs when the result of the index test is used in establishing the final diagnosis (i.e.&nbsp;it forms part of the reference standard).</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Observer</td>
<td><blockquote class="blockquote">
<p>Variation</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>The interpretation placed upon a test result may vary between observers and this can affect estimates of test accuracy. The reproducibility of a test within (intra) and between (inter) observers affects its applicability in practice.</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p>Analysis</p>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 7%">
<col style="width: 78%">
</colgroup>
<thead>
<tr class="header">
<th><p>Handling of</p>
<p>un-interpretable results</p></th>
<th><blockquote class="blockquote">
<p>Bias</p>
</blockquote></th>
<th><blockquote class="blockquote">
<p>Diagnostic tests fail or produce un-interpretable results with varying frequency. Study participants for whom a test result could not be obtained are</p>
<p>often removed from reported analyses. This may lead to a biased assessment of test performance.</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Arbitrary choice of</td>
<td><blockquote class="blockquote">
<p>Variation</p>
</blockquote></td>
<td><blockquote class="blockquote">
<p>The choice of a threshold value based upon that</p>
</blockquote></td>
</tr>
<tr class="even">
<td>threshold value (the</td>
<td></td>
<td><blockquote class="blockquote">
<p>which maximises sensitivity and specificity for the</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>diagnostic threshold is</td>
<td></td>
<td><blockquote class="blockquote">
<p>study data may result in exaggerated estimates of</p>
</blockquote></td>
</tr>
<tr class="even">
<td>derived from the same</td>
<td></td>
<td><blockquote class="blockquote">
<p>test performance. The test may perform less well at</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>data set in which test</td>
<td></td>
<td><blockquote class="blockquote">
<p>the chosen threshold when evaluated in a new</p>
</blockquote></td>
</tr>
<tr class="even">
<td>performance is evaluated)</td>
<td></td>
<td><blockquote class="blockquote">
<p>independent patient set.</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p>QUADAS is a generic tool, which may be adapted to optimize its usefulness for specific topic areas. Researchers should, therefore, also consider in advance whether all QUADAS items are relevant to their topic area, and whether there are any additional items that are not included in QUADAS.57 For example, disease progression bias may not be a relevant issue where the clinical course of the target condition is slow; when comparing the performance of imaging tests, or other tests which require subjective interpretation by the operator, the impact of observer variation may need to be considered as variation in test performance with individual operators of the same test (e.g.&nbsp;different individuals conducting and/or interpreting an ultrasound examination) can exceed, and therefore mask, a difference in performance between two different tests (e.g.&nbsp;ultrasound and magnetic resonance imaging).58, 59</p>
<table class="caption-top table">
<caption>The QUADAS items</caption>
<colgroup>
<col style="width: 66%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>QUADAS criterion</th>
<th><blockquote class="blockquote">
<p>Bias/variation assessed</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Was the spectrum of patients representative of the patients who will receive the test in practice?</td>
<td><blockquote class="blockquote">
<p>Population characteristics (demographic, severity and prevalence of disease)</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Were the selection criteria clearly described?</td>
<td><blockquote class="blockquote">
<p>Participant selection</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Is the reference standard likely to correctly classify the target condition?</td>
<td><blockquote class="blockquote">
<p>Use of an inappropriate reference standard</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Is the time period between reference standard and index test short enough to be reasonably sure that the target condition did not change between the two tests?</td>
<td><blockquote class="blockquote">
<p>Disease progression</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Did the whole sample or random selection of the sample receive verification using a reference standard of diagnosis?</td>
<td><blockquote class="blockquote">
<p>Partial verification</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Did the patients receive that same reference standard regardless of the index test results?</td>
<td><blockquote class="blockquote">
<p>Differential verification</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Was the reference standard independent of the index test?</td>
<td><blockquote class="blockquote">
<p>Incorporation</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Was the execution of the index test described in sufficient detail to permit replication?</td>
<td><blockquote class="blockquote">
<p>Test execution</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Was the execution of the reference standard described in sufficient detail to permit replication?</td>
<td></td>
</tr>
<tr class="even">
<td>Were the index test results interpreted without knowledge of the results of the reference standard?</td>
<td><blockquote class="blockquote">
<p>Test review</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Were the reference standard results interpreted without knowledge of the results of the index test?</td>
<td><blockquote class="blockquote">
<p>Diagnostic review</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Were the same clinical data available when the test results were interpreted as would be available when the test is used in practice?</td>
<td><blockquote class="blockquote">
<p>Clinical review</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Were un-interpretable/intermediate test results reported?</td>
<td><blockquote class="blockquote">
<p>Handling of un-interpretable or missing results</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Were withdrawals from the study explained?</td>
<td></td>
</tr>
</tbody>
</table>
<p>It is worth noting that the information that can be derived from the quality assessment of test accuracy studies is often limited by poor reporting. Where QUADAS items are scored ‘unclear’ the researcher cannot be certain whether this indicates poor methods with the attendant consequences for bias/variation, or simply poor reporting of a methodologically sound study. The STARD initiative60 has proposed standards for the reporting of diagnostic accuracy studies. If these standards are widely adopted and lead to a general improvement in the reporting of test accuracy studies, reviewers will increasingly be able to assess methodological quality rather than the quality of reporting.</p>
</section>
<section id="synthesis" class="level3" data-number="3.1.5">
<h3 data-number="3.1.5" class="anchored" data-anchor-id="synthesis"><span class="header-section-number">3.1.5</span> Synthesis</h3>
<p>A thorough investigation of heterogeneity should be undertaken before deciding if studies are suitable for combining in a meta-analysis and if so what method to use. Clinical and methodological differences such as patient populations, tests, study design and study conduct, should be considered in addition to statistical variation in the accuracy measures reported by studies. Where a meta-analysis is not considered clinically or statistically meaningful, a structured narrative synthesis can be carried out which can include the presentation of results in one or more graphical formats.61 For example the results of individual studies can be plotted in ROC space, as in Figure 2.4, whether or not a summary curve is included. As well as stratification by index test characteristics, reviews which focus on determining the optimal diagnostic pathway for a condition, rather than the diagnostic performance of a single test, should consider structuring narrative reports to represent the order in which tests would be applied in clinical practice. Reviews which consider differential diagnosis from a common presenting symptom, such as a review of the performance tests to determine the cause of haematuria, should consider stratifying the narrative by target condition with the most common diagnosis addressed first. These approaches aim to increase readability for practitioners and can equally be applied to the structure of reports which include meta-analyses.</p>
<p>Assessment of statistical heterogeneity</p>
<p>Threshold effect</p>
<p>A source of heterogeneity unique to test accuracy studies, which requires careful assessment, arises from the choice of the threshold used to define a positive result.62 Even when different thresholds are not explicitly defined, variation in interpretation by observers may result in implicit variation in threshold. This can be assessed visually using a ROC space plot and statistically by measuring the correlation between sensitivity and specificity. However, statistical tests may be unreliable where studies in a systematic review have small sample sizes; threshold effect may be present but undetected by statistical tests. A ROC space plot is a plot of the ‘true positive rate’ (sensitivity) from each study against the ‘false positive rate’ (1 - specificity). If a threshold effect exists then the plot will show a curve (as the threshold decreases the sensitivity will increase and the specificity will decrease). This curve follows the operating characteristics of the test at varying thresholds.</p>
<p>Figure 2.4 clearly shows a curve in the top left hand corner of the plot, indicating the presence of a threshold effect. The presence of a threshold effect can also be investigated using a regression62 or a hierarchical summary ROC (HSROC) model63 which are described in more detail in the meta-analysis section below.</p>
<p>Heterogeneity of individual diagnostic accuracy measures</p>
<p>Variability amongst each of the individual measurements (sensitivity, specificity, positive and negative likelihood ratio, and DOR) can be assessed using the same methods as for other study types. Forest plots can be used to visually assess differences between studies, although these will not show any threshold effects. Paired forest plots should be used when illustrating paired outcome measures such as sensitivity and specificity. Use of statistical tests of heterogeneity does not reliably indicate absence of heterogeneity and it is generally advisable to assume the presence of heterogeneity and to fit models which aim to describe and account for it.</p>
<section id="meta-analysis" class="level4" data-number="3.1.5.1">
<h4 data-number="3.1.5.1" class="anchored" data-anchor-id="meta-analysis"><span class="header-section-number">3.1.5.1</span> Meta-analysis</h4>
<p>The meta-analysis of diagnostic accuracy studies requires the use of some specific statistical methods which differ from standard methods. Meta-analysis has two main aims: to obtain a pooled measure of diagnostic accuracy and in the case of summary ROC (SROC) models, to explore the heterogeneity amongst studies. Diagnostic accuracy is usually represented by a pair of related measurements, for example: sensitivity and specificity; positive and negative likelihood ratio; and this relationship needs to be incorporated into the analysis methods.</p>
<p>Pooling individual diagnostic accuracy measures</p>
<p>A robust approach to combining data and estimating the underlying relationship between sensitivity and specificity is the construction of an SROC curve. Methods that involve pooling sensitivities and specificities from individual studies, or combining positive and negative likelihood ratios fail to account for the paired nature of the parameters, and should generally be avoided. However, where only one parameter (e.g.&nbsp;sensitivity, but not specificity) is presented, simple pooling of proportions is the only option. Assessment of single parameters is usually inappropriate, but is sometimes used when there is a specific clinical reason why only one parameter should be the focus of interest.</p>
<p>Diagnostic odds ratios can be pooled using standard fixed or random-effects methods for pooling odds ratios. However, these methods do not help estimate average sensitivity and specificity and may produce erroneous results where there is a relationship between DOR and threshold.64</p>
<p>Predictive values should not be pooled in meta-analyses as they are affected by the prevalence of disease in the populations of the studies. Overall predictive values are sometimes calculated using estimates of prevalence from the included studies and pooled estimates of likelihood ratios. However, the potentially misleading nature of such estimates should be considered carefully.</p>
<p>Simple methods of estimating summary ROC curves</p>
<p>The Moses-Littenburg regression based method,62 has been used as a simple method of pooling study results in the presence of a suspected threshold effect. It can be used in preliminary exploratory analyses and is helpful in understanding the data.65 However, it has limitations and should not be used to obtain summary estimates of sensitivity and specificity. The usual regression model assumptions are not met.66, 67 It also assumes that there is only one result per study and so cannot deal adequately with studies which have multiple data sets per test (e.g.&nbsp;data for a number of different thresholds).</p>
<p>It is possible to pool ROC curves, or the AUC from individual studies although this is not recommended and would not be practical in the case where some studies reported data for a single threshold and others presented data (or a ROC curve) for a number of thresholds.21</p>
<p>Optimal methods of modelling SROC curves</p>
<p>Statistical models, including hierarchical and bivariate models, have been developed for the estimation of SROC curves in the meta-analysis of test accuracy results. The HSROC model63 accounts for both within- and between-study variation in true positive and false positive rates. The model estimates parameters for the threshold, log DOR and the shape of the underlying ROC curve. It has been shown that it is possible to fit this model using statistical package SAS, and that this method provides results that agree with the more complex Bayesian methods.68 The HSROC model can be extended to deal with studies that provide results for more than one threshold, but programming</p>
<p>is challenging. The bivariate model67 analyses sensitivity and specificity jointly, therefore retaining the paired nature of the original data (a STATA command function has recently been produced for the bivariate model). The HSROC and bivariate models have been</p>
<p>shown to produce equivalent results in the absence of other study-level covariates.69 It is recommended that meta-analyses using these models should be undertaken with the assistance of a statistician.</p>
<p>Exploring heterogeneity</p>
<p>Sources of methodological and/or clinical heterogeneity can be explored using subgroup analyses. Ideally subgroups should be planned at the protocol stage. However, where this is dependent upon what data are available, and an adaptive process is needed,</p>
<p>this should be stated clearly in the protocol. Results from different groups, for example different tests, or study designs, can be visually assessed by using a ROC space plot with different symbols. Figure 2.5 illustrates the divergent accuracy results between different study designs from a systematic review of faecal occult blood tests used in screening for colorectal cancer,15 which indicates that two-gate studies (white circles) overestimate test performance compared with single-gate studies (black circles).</p>
<p>HSROC and bivariate models can be used to assess heterogeneity by including covariates. These models allow investigation of the effect of covariates on sensitivity and specificity separately, rather than just the DOR (although this can still be obtained). Further research is needed to determine which SROC models are the most appropriate for the exploration of heterogeneity as the choice of model may depend on which accuracy measure (DOR, sensitivity, specificity) is most affected.69 An overview of the different methods used to explore heterogeneity in systematic reviews of diagnostic test accuracy is available.70 It should be noted that, as for meta-regression analyses of other study designs, these analyses are exploratory, can only include covariates reported by</p>
<p>the studies and should not be conducted if there are only a small number of studies (a minimum of 10 studies per covariate is needed). Regardless of the approach used, study-level factors to be examined should be defined in the protocol and aspects of methodological quality, (e.g.&nbsp;QUADAS items) should be considered individually, rather than as overall quality scores.45, 48</p>
</section>
<section id="software" class="level4" data-number="3.1.5.2">
<h4 data-number="3.1.5.2" class="anchored" data-anchor-id="software"><span class="header-section-number">3.1.5.2</span> Software</h4>
<p>Methods for calculating outcome measures, assessing heterogeneity, producing plots (both with and without summary estimates) and undertaking exploratory analyses using the Moses model are available in a user-friendly form in the Meta-DiSc software <a href="http://www.hrc.es/investigacion/metadisc_en.html">(www.hrc.es/investigacion/metadisc_en.html).71</a>.71) Systematic reviews of diagnostic accuracy studies have been incorporated in version 5.0 of the Cochrane Review Manager software. More specialist statistical software packages, such as STATA, SAS or WINBUGS, are needed to fit HSROC/bivariate models and the support of a statistician with knowledge of the field is generally recommended.</p>
</section>
</section>
<section id="presentation-of-results" class="level3" data-number="3.1.6">
<h3 data-number="3.1.6" class="anchored" data-anchor-id="presentation-of-results"><span class="header-section-number">3.1.6</span> Presentation of results</h3>
<p>When presenting the results of a systematic review of clinical tests it is important to consider how these results will be understood by clinicians and applied in practice. The understanding of and preferences for measures of test performance by clinicians has been the subject of much research and comment.72-74 The ‘best’ method remains elusive but some general points, which may improve clarity and aid interpretation, are given below.</p>
<p>The presentation of diagnostic measures should be similar for both narrative and meta- analytic approaches, with graphical representation and/or tabulation of individual study results and additional results presented if meta-analysis was performed. Sufficient detail of the tests, participants, study design and conduct should be presented in tables.75</p>
<p>The 2 x 2 table results of TP, FP, FN and TN together with sensitivity and specificity, as a minimum should be presented for each study. The choice of accuracy measures presented depends on the aims and anticipated users of the review. Sensitivity and</p>
<p>specificity and likelihood ratios are measures of test performance; likelihood ratios may be more useful in a clinical setting as they can be used to calculate the probability of disease given a particular test result, whereas DORs are difficult to interpret clinically.22 Forest plots or ROC space plots provide useful visual summaries and can be easier</p>
<p>to interpret than large tables of numbers. The ranges should be presented when summarising results which have not been subject to meta-analytic pooling. For paired results it may be useful to also present the corresponding measure for the studies at each end of the range, e.g.&nbsp;‘sensitivity ranged from 48% (at a specificity of 80%) to 92% (at a specificity of 70%)’.</p>
<p>If a meta-analysis was undertaken then the presentation of results depends on the methods used. If sensitivity or specificity have been pooled as individual measures then the summary estimate together with the 95% confidence intervals should be presented. If an SROC model has been used then the relevant SROC curve(s) should be presented. Where the performance of a number of index tests is being compared it may</p>
<p>be useful to present multiple SROC curves (or un-pooled data sets) on the same plot. Summary measures of overall diagnostic accuracy, such as AUC or the Q* point (the point on the curve where sensitivity and specificity are equal) may also be presented. However, the relevance of the Q* point is debatable, as its use may lead to summary estimates of sensitivity and specificity outside the values in the original studies.67 Pairs of sensitivity and specificity values can also be read from the SROC curve and presented as a number of summary points in order to provide an overall description of the curve. The estimated SROC curves should also be presented if HSROC or bivariate models have been used. These models enable the calculation of summary estimates of sensitivity</p>
<p>and specificity, which should be reported along with their 95% confidence intervals. Although the use of HSROC or bivariate models to generate summary likelihood ratios is not recommended,76 where likelihood ratios are considered helpful to interpretation, summary likelihood ratios can be calculated from the pooled estimates of sensitivity and specificity generated by these models. For results from a HSROC or bivariate model, as these retain the paired nature of sensitivity and specificity, a region can be plotted around the summary operating point which represents the 95% confidence intervals of both measures.67 Confidence interval regions can also be plotted for the results of individual studies, but care is required to ensure that these are not mistakenly interpreted as representations of study weighting. Both models can also be used to plot a prediction region; this is the region which has a particular probability of including the true sensitivity and specificity of a future study.69</p>
<p>Summary: Diagnostic studies</p>
<ul>
<li><p>Researchers planning systematic reviews of test accuracy should give careful consideration to context (e.g.&nbsp;is there evidence of a prognostic link between the target condition and preventable morbidity/mortality).</p></li>
<li><p>Diagnostic tests should be evaluated in patients who are representative of those in whom the test will be used in practice; ideally a consecutive or</p></li>
</ul>
<blockquote class="blockquote">
<p>randomly selected series whose diagnosis is unknown at the time of testing.</p>
</blockquote>
<ul>
<li><p>Careful consideration should be given to what is the appropriate reference standard to establish diagnosis.</p></li>
<li><p>Difficulties in searching bibliographic databases for test accuracy studies and the lack of suitable methodological search filters mean that more specific searches carry a risk of missing studies. Searches based upon index test and target condition, which are designed to maximise sensitivity, are therefore recommended.</p></li>
<li><p>Test accuracy studies are often poorly reported, hampering data extraction, quality assessment and synthesis.</p></li>
<li><p>Though often unable to provide a definitive estimate of test accuracy, systematic reviews can highlight important gaps in the evidence base and aid in the design of future studies.</p></li>
</ul>
</section>
</section>
<section id="prognostic-tests" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="prognostic-tests"><span class="header-section-number">3.2</span> Prognostic tests</h2>
<p>Prognostic markers (biomarkers) are characteristics that help to identify or categorise people with different risks of specific future outcomes. They may be simple clinical measures such as body mass index, but are more often pathological, biochemical, molecular or genetic measures or attributes. Identifying those who are or who are not at risk can facilitate intervention choice, and aid patient counselling.</p>
<p>Prognostic research has to date received much less attention than research into therapeutic or diagnostic areas, and an evidence-based approach to the design, conduct and reporting of primary studies of prognostic markers is needed.77 Reviews have shown that primary prognostic studies are often of poor quality.78</p>
<p>Synthesis of prognostic studies is a relatively new and evolving area in which the methods are less well developed than for reviews of therapeutic interventions or of diagnostic accuracy, and available reviews have often been of poor quality.79-82</p>
<p>Although numbers of completed prognostic reviews are relatively few,83 they are becoming more common. Of 294 reviews of prognostic studies published since 1966, almost all have appeared since 1996, occurring most commonly in cancer (15%), musculoskeletal disorders and rheumatology (13%), cardiology (10%), neurology (10%), and obstetrics (10%).79 Available reviews often include large numbers of studies and patients. For example, some reviews in cancer and cardiovascular disease have reported data on over 10,000 patients for a single marker.84-87</p>
<p>This section focuses mainly on reviews of studies of potential prognostic markers and builds on previous work.88 Given that this is a developing area where methods and approaches will undoubtedly change rapidly, this section presents a discussion rather than firm guidance. Systematic reviews of studies which develop a prognostic model (risk score) are not considered here.</p>
<section id="defining-the-review-question-setting-inclusion-criteria" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="defining-the-review-question-setting-inclusion-criteria"><span class="header-section-number">3.2.1</span> Defining the review question: setting inclusion criteria</h3>
<p>Defining the review question and setting inclusion criteria should be approached in the same way as set out in Chapter 1, Section 1.2 The review protocol. However, some aspects of methodology require particular attention when planning a systematic review of prognostic studies, and should be considered at an early stage.</p>
<section id="populationstudy-design" class="level4" data-number="3.2.1.1">
<h4 data-number="3.2.1.1" class="anchored" data-anchor-id="populationstudy-design"><span class="header-section-number">3.2.1.1</span> Population/study design</h4>
<p>Patients included in a prognostic study are usually selected as an ‘inception’ cohort of patients identified very early in the course of their disease, perhaps at diagnosis. Even if the cohort is identified retrospectively, it should be followed forwards in time from a particular point, such as diagnosis or (if relevant) randomisation. The case-control design is liable to bias.89 Careful thought as to what study designs will be included in the review is needed.</p>
</section>
<section id="intervention" class="level4" data-number="3.2.1.2">
<h4 data-number="3.2.1.2" class="anchored" data-anchor-id="intervention"><span class="header-section-number">3.2.1.2</span> Intervention</h4>
<p>Although often ignored in prognostic studies, if the intervention that patients receive varies on account of perceived prognosis, this precludes an unbiased assessment of the prognostic ability of a marker (unless alternative interventions are equally effective).</p>
<p>Although the intervention effect may be small compared to the effect of important prognostic variables and consequently will have little impact on findings, ideally, prognostic variables should be evaluated in a cohort of patients treated the same way, or that have been included in an RCT.90, 91 The intervention received is rarely reported in primary studies.</p>
</section>
</section>
<section id="defining-the-review-question-other-considerations" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="defining-the-review-question-other-considerations"><span class="header-section-number">3.2.2</span> Defining the review question: other considerations</h3>
<section id="publication-bias-and-sample-size" class="level4" data-number="3.2.2.1">
<h4 data-number="3.2.2.1" class="anchored" data-anchor-id="publication-bias-and-sample-size"><span class="header-section-number">3.2.2.1</span> Publication bias and sample size</h4>
<p>Evidence of publication and associated reporting biases is accumulating for prognostic studies.92, 93 For example, in a systematic review of studies of a marker Bcl2 in non- small cell lung cancer, almost all the smaller studies showed a statistically significant relationship between Bcl2 and risk of dying, with large hazard ratios, whereas the three large studies were all nonsignificant and showed a much smaller effect.94 A recent review of the prognostic importance of TP53 status in head and neck cancer showed clearly that published studies had larger effects than unpublished studies.80 This is in keeping with the belief that epidemiological studies are more prone to publication bias than randomised trials.80, 95 Publication bias may indeed be worse as many studies are based on retrospective analysis of existing clinical databases, and so in essence they do not really exist until published.</p>
<p>Adequate sample size is equally as important for prognostic studies as for clinical trials, but has received little attention. For example, three quarters of 47 papers reporting prognostic studies in osteosarcoma had fewer than 100 cases.96 The likely presence of publication bias means that small studies are unreliable and for prognostic reviews there is a good argument for omitting small studies from meta-analysis, for example those with fewer than 100 patients or even 100 events.</p>
<p>Selective reporting of outcomes is also a concern in prognostic studies. For example, in cancer studies the two principal outcomes are time to death (overall survival) and time to recurrence of disease (‘disease-free survival’). Many studies, such as in the case- study in Section 2.3.7, report only one of these outcomes, which may have been chosen in relation to the findings.</p>
</section>
<section id="cutpoints" class="level4" data-number="3.2.2.2">
<h4 data-number="3.2.2.2" class="anchored" data-anchor-id="cutpoints"><span class="header-section-number">3.2.2.2</span> Cutpoints</h4>
<p>Most markers are continuous measurements. However, it is very common in cancer, and occasionally in other fields, for continuous marker values to be converted to binary variables whereby each patient is characterised as having a high or low value. Dichotomisation is statistically inefficient,97, 98 but in some fields, notably cancer, it is ubiquitous. Dichotomising does not introduce bias if the split is made at the median or some other pre-specified percentile. However, if the cutpoint is chosen based on analysis of the data, by splitting at the value which produced the largest difference in outcome between categories, then severe bias will be introduced.99 Significant findings associated with a data-derived cutpoint will be overoptimistic, perhaps by a large amount. Such studies may best be excluded from any meta-analysis.</p>
<p>Many reports do not state how cutpoints were chosen. When the numbers above and below the cutpoint differ or are not stated, and when the chosen cutpoint is unique to that study, it may be unwise to assume that the choice was made in a valid way.</p>
</section>
<section id="ipd-vs-summary-data" class="level4" data-number="3.2.2.3">
<h4 data-number="3.2.2.3" class="anchored" data-anchor-id="ipd-vs-summary-data"><span class="header-section-number">3.2.2.3</span> IPD vs summary data</h4>
<p>Several authors have noted the considerable advantages of obtaining individual patient data (IPD),100, 101 and it is clear that IPD could be especially valuable for systematic reviews of prognostic markers. In addition to the usual advantages of IPD over published summary statistics100 (see Appendix 1), there are some specific advantages. Firstly, it may allow inclusion of more studies as not all studies provide the necessary outcome data. Secondly, it allows all data sets to be analysed in a consistent way, which in this case means adjusting for the same variables and using the same analysis method. Thirdly, the marker values can be kept continuous, increasing statistical power and informativeness. Finally, it is possible to conduct analyses restricted to clinical subgroups, for example by stage of disease.</p>
<p>The natural extension of standard systematic reviews would be to try to collect IPD from all identified studies, whether published or not. Although this has been attempted for prognostic studies it has been found to be very time consuming.102, 103 Concerns about publication bias and the overhead attached to identifying, obtaining and processing each data set have led to the suggestion that for a prognostic meta-analysis of IPD, restriction to only the larger studies or perhaps those carried out in one region104 would be preferable to one based on summary published data that included every published study.77</p>
</section>
</section>
<section id="identifying-research-evidence-1" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="identifying-research-evidence-1"><span class="header-section-number">3.2.3</span> Identifying research evidence</h3>
<p>Identifying prognostic studies is hampered by an absence of standard descriptors and indexing terms. In recent years search strategies have been developed to identify prognostic studies in MEDLINE105 (see Box 2.1) and EMBASE.106 An improved search strategy for MEDLINE, CINAHL and HealthStar has recently been presented107 but is as yet unpublished.</p>
</section>
<section id="data-extraction-1" class="level3" data-number="3.2.4">
<h3 data-number="3.2.4" class="anchored" data-anchor-id="data-extraction-1"><span class="header-section-number">3.2.4</span> Data extraction</h3>
<p>Aspects of particular relevance in prognostic studies include recording how the measurements were made (e.g.&nbsp;equipment or assay used), length of follow-up, distribution of the marker, any cutpoints used (with rationale), amount of missing data, methods of statistical analysis, including variables adjusted for, and the number of participants included in the final model.</p>
<p>A prognostic study with a dichotomous endpoint, such as 30 day mortality after surgery, is statistically no different from a diagnostic accuracy study and poses no additional difficulties for extraction of results. Random-effects endpoints are desirable but there are often difficulties in extracting the log hazard ratio and its standard error from published reports. Guidance on how to estimate these quantities when they are not given explicitly is available.108</p>
</section>
<section id="risk-of-bias-assessment-1" class="level3" data-number="3.2.5">
<h3 data-number="3.2.5" class="anchored" data-anchor-id="risk-of-bias-assessment-1"><span class="header-section-number">3.2.5</span> Risk of bias assessment</h3>
<p>The assessment of the appropriateness of the methodology used in the primary studies is a key element of any systematic review, but has been performed in a minority of cases in prognostic systematic reviews.79, 109 This may reflect the absence of widely agreed criteria for assessing the quality of prognostic studies. Although it is not good practice to use quality as an inclusion criterion, an evaluation of reviews79 found that this was done in 55/163 (34%) reviews.</p>
<p>Reviews of prognostic studies have demonstrated that generally the methodological quality of included studies is poor. For example, one review which assessed 104 prognostic studies in kidney disease against eight criteria, found that three-quarters of the studies satisfied four or fewer of the eight criteria.78</p>
<p>As with other study designs, quality scores are problematic.48, 110, 111 For example, a quality score was developed which evaluated aspects of study methodology grouped into four main categories: the scientific design; laboratory methodology; the generalisability of the results; and the analysis of the study data.112 No details were provided of the development of this scoring system, and as it includes elements of both methodology and reporting it is hard to interpret. Further, for many of the items (e.g.&nbsp;‘source of samples’) there is no explanation of the coding scheme. It is preferable to consider specific aspects of methodology related to the risk of bias.</p>
<p>Despite the lack of empirical evidence to support the importance of particular study features affecting the reliability of study findings, especially the risk of bias, theoretical considerations and common sense point to several methodological aspects that are likely to be important.</p>
<section id="generic-criteria" class="level4" data-number="3.2.5.1">
<h4 data-number="3.2.5.1" class="anchored" data-anchor-id="generic-criteria"><span class="header-section-number">3.2.5.1</span> Generic criteria</h4>
<p>Table 2.3 lists methodological features that are likely to be important for the internal validity of prognostic studies.88 The items are not phrased as questions but rather as domains of likely importance. Most authors have presented their checklists as questions. For example, ‘Was there a representative and well-defined sample of patients at a similar point in the course of the disease?’, taken from a checklist produced by the Evidence-Based Medicine Working Group,113 is a question that includes three elements from Table 2.3. This checklist is widely quoted, for example in a guide for clinicians,114 but it omits several of the items in Table 2.3.</p>
<p>It is generally agreed that to be reliable (and clinically interpretable) a prognostic study requires a well-defined (‘inception’) cohort of patients at the same stage of their disease, preferably at diagnosis.115 This also illustrates the more general requirement that the cohort can be clearly described, which is necessary for the study to have external validity.</p>
</section>
<section id="context-specific-criteria" class="level4" data-number="3.2.5.2">
<h4 data-number="3.2.5.2" class="anchored" data-anchor-id="context-specific-criteria"><span class="header-section-number">3.2.5.2</span> Context-specific criteria</h4>
<p>There may also be context-related quality aspects that should be considered in individual reviews. For example, some studies may have used inferior laboratory methods to measure the marker. However, it is important to distinguish aspects of a study that might be a cause of bias, and hence be genuinely a matter of quality, and those that just reflect variation in study conduct but where no bias is likely. Examples of the latter are patient inclusion criteria, length of follow-up, and choice of measuring device or assay kit. Such factors may well be a cause of heterogeneity and it may be prudent to perform separate (subgroup) analyses to investigate whether they are in fact of importance. There are several published checklists for assessing prognostic studies in cancer.116-118</p>
</section>
<section id="implementing-quality-assessment" class="level4" data-number="3.2.5.3">
<h4 data-number="3.2.5.3" class="anchored" data-anchor-id="implementing-quality-assessment"><span class="header-section-number">3.2.5.3</span> Implementing quality assessment</h4>
<p>Quality assessment in prognostic systematic reviews is often incomplete and there is wide variation in current practice. A review of reviews identified 14 methodological domains grouped within six dimensions relating to the risk of bias of prognostic studies.</p>
<p>A framework for assessing the internal validity of articles describing prognostic factor studies88</p>
<table class="caption-top table">
<colgroup>
<col style="width: 29%">
<col style="width: 70%">
</colgroup>
<thead>
<tr class="header">
<th>Study feature</th>
<th><blockquote class="blockquote">
<p>Qualities sought</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sample of patients</td>
<td><blockquote class="blockquote">
<p>Inclusion criteria defined Sample selection explained</p>
<p>Adequate description of diagnostic criteria</p>
<p>Clinical and demographic characteristics fully described Representative</p>
<p>Assembled at a common (usually early) point in the course of their disease</p>
<p>Complete</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Follow-up of patients</td>
<td><blockquote class="blockquote">
<p>Sufficiently long</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Outcome</td>
<td><blockquote class="blockquote">
<p>Objective</p>
<p>Unbiased (e.g.&nbsp;assessment blinded to prognostic information) Fully defined</p>
<p>Appropriate</p>
<p>Known for all or a high proportion of patients</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Prognostic variable</td>
<td><blockquote class="blockquote">
<p>Fully defined, including details of method of measurement if relevant Precisely measured</p>
<p>Available for all or a high proportion of patients If relevant, cutpoint(s) defined and justified</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Analysis</td>
<td><blockquote class="blockquote">
<p>Continuous predictor variable analysed appropriately Statistical adjustment for all important prognostic factors</p>
</blockquote></td>
</tr>
<tr class="even">
<td>Intervention subsequent to inclusion in cohort</td>
<td><blockquote class="blockquote">
<p>Fully described</p>
<p>Intervention standardised or randomised</p>
</blockquote></td>
</tr>
</tbody>
</table>
</section>
<section id="quality-of-reporting" class="level4" data-number="3.2.5.4">
<h4 data-number="3.2.5.4" class="anchored" data-anchor-id="quality-of-reporting"><span class="header-section-number">3.2.5.4</span> Quality of reporting</h4>
<p>Assessment of study quality is often seriously hampered by poor reporting of methodological details, as is well known for other types of research. The REporting recommendations for tumour MARKer prognostic studies (REMARK) initiative has proposed guidelines for reporting prognostic studies in cancer, most of which apply to any medical context.121 Adoption of the REMARK guidelines should lead to improved reporting of prognostic studies.</p>
<p>System for assessing quality of prognostic factor studies, with proportion of 153 prognostic systematic reviews meeting each item79</p>
<table class="caption-top table">
<colgroup>
<col style="width: 55%">
<col style="width: 12%">
<col style="width: 22%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th>Potential bias</th>
<th style="text-align: center;"><blockquote class="blockquote">
<p>% reviews adequately assessing bias</p>
</blockquote></th>
<th><blockquote class="blockquote">
<p>Domains addressed</p>
</blockquote></th>
<th style="text-align: center;"><blockquote class="blockquote">
<p>% reviews assessing domain</p>
</blockquote></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><ol type="1">
<li>Study participation</li>
</ol>
<p>The study sample represents the population of interest on key characteristics, sufficient to limit potential bias to the results</p></td>
<td style="text-align: center;">55</td>
<td><ol type="1">
<li><p>Source population clearly defined</p></li>
<li><p>Study population described</p></li>
<li><p>Study population represents source population or population of interest</p></li>
</ol></td>
<td style="text-align: center;"><blockquote class="blockquote">
<p>50</p>
</blockquote>
<p>21</p>
<blockquote class="blockquote">
<p>50</p>
</blockquote></td>
</tr>
<tr class="even">
<td><p>2. Study attrition</p>
<p>Loss to follow-up (from sample to study population) is not associated with key characteristics, sufficient to limit potential bias (i.e., the study data adequately represent the sample)</p></td>
<td style="text-align: center;">42</td>
<td><ol start="4" type="1">
<li><p>Completeness of follow-up described</p></li>
<li><p>Completeness of follow-up adequate</p></li>
</ol></td>
<td style="text-align: center;"><p>19</p>
<blockquote class="blockquote">
<p>42</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><p>3. Prognostic factor measurement</p>
<p>The prognostic factor of interest is adequately measured</p></td>
<td style="text-align: center;">59</td>
<td><ol start="6" type="1">
<li>Prognostic factors defined in study participants to</li>
</ol>
<blockquote class="blockquote">
<p>sufficiently limit potential bias</p>
</blockquote>
<ol start="7" type="1">
<li>Prognostic factors measured appropriately</li>
</ol></td>
<td style="text-align: center;"><p>31</p>
<blockquote class="blockquote">
<p>59</p>
</blockquote></td>
</tr>
<tr class="even">
<td>4. Outcome measurement The outcomes of interest are adequately measured in study participants to sufficiently limit potential bias</td>
<td style="text-align: center;">51</td>
<td><ol start="8" type="1">
<li><p>Outcome defined</p></li>
<li><p>Outcome measured appropriately</p></li>
</ol></td>
<td style="text-align: center;"><p>42</p>
<blockquote class="blockquote">
<p>51</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><p>5. Confounding measurement and account</p>
<p>Important potential confounders are appropriately accounted for, limiting potential bias with respect to the prognostic factor of interest</p></td>
<td style="text-align: center;">13</td>
<td><blockquote class="blockquote">
<p>10. Confounders defined and measured</p>
<p>11. Confounding accounted for</p>
</blockquote></td>
<td style="text-align: center;"><p>21</p>
<p>53</p></td>
</tr>
<tr class="even">
<td><p>6. Analysis</p>
<p>The statistical analysis is appropriate for the design of the study, limiting potential for presentation of invalid results</p></td>
<td style="text-align: center;">33</td>
<td><ol start="12" type="1">
<li><p>Analysis described</p></li>
<li><p>Analysis appropriate</p></li>
<li><p>Analysis provides sufficient presentation of data</p></li>
</ol></td>
<td style="text-align: center;"><p>8</p>
<blockquote class="blockquote">
<p>33</p>
</blockquote>
<p>32</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="synthesis-1" class="level3" data-number="3.2.6">
<h3 data-number="3.2.6" class="anchored" data-anchor-id="synthesis-1"><span class="header-section-number">3.2.6</span> Synthesis</h3>
<section id="outcome-measures-1" class="level4" data-number="3.2.6.1">
<h4 data-number="3.2.6.1" class="anchored" data-anchor-id="outcome-measures-1"><span class="header-section-number">3.2.6.1</span> Outcome measures</h4>
<p>In prognostic studies the focus of interest is what may happen in the future. It is natural, therefore, that most prognostic studies have outcomes that are the time to a specific event, such as death. However, some prognostic studies with dichotomous outcomes may inappropriately ignore the time element. For example, a study looking at death within three years may classify all patients as dead or alive, but those patients who are lost to follow-up before three years (i.e.&nbsp;have censored survival times) cannot be so classified and may be excluded. One exception is studies of prognosis in pregnancy where outcomes often relate to the birth of the baby (e.g.&nbsp;predicting caesarean section or pre-term birth). Such outcomes are genuinely dichotomous and can be analysed in the same way as a study of diagnostic accuracy.</p>
<p>Meta-analysis of time-to event outcomes of aggregate data derived from publications is usually done using the generic inverse-variance approach and may use a fixed effect or random-effects model (see Chapter 1, Section 1.3.5 Data synthesis). This type of analysis and extensions have been discussed, as has investigation of heterogeneity in such studies.122, 123 Although the preferred statistical summary is the hazard ratio (HR) (see Chapter 1, Section 1.3.5 Data synthesis) many publications do not report the HR or the information needed to calculate it. Consequently, some of the identified studies cannot be included in the synthesis. Furthermore, non-reporting of appropriate statistical summary measures may be more likely if the marker was found not to be statistically significantly related to outcome, leading to bias. Statistical methods for analysing IPD time-to-event data have been compared,124 and methods have been published for combining IPD with published summary data.125</p>
<p>When all studies have reported data as dichotomous or continuous, meta-analysis may be relatively straightforward. However, if there is a mixture of binary, multi-category, and continuous representation of the same marker, meta-analysis will be problematic and expert input will be advisable. Similar problems have been reported in meta- analysis of epidemiological studies.126</p>
<p>In principle researchers may need to combine estimates of a marker that is kept continuous in some studies and dichotomised in others. It is important to note that the hazard ratios for those two cases are not comparable so they should not be combined. There is a related literature on combining data on dose-response relationships in epidemiology.127-129</p>
</section>
<section id="adjustment-for-other-variables" class="level4" data-number="3.2.6.2">
<h4 data-number="3.2.6.2" class="anchored" data-anchor-id="adjustment-for-other-variables"><span class="header-section-number">3.2.6.2</span> Adjustment for other variables</h4>
<p>In RCTs the groups being compared are expected to be very similar with regard to prognostic factors (baseline characteristics) through the use of a random sequence of intervention assignment. In non-randomised studies there is no such safeguard and we should expect the groups being compared to differ in various ways. In prognostic studies we are comparing individuals with different levels of a marker, whether binary or continuous. That comparison could easily be biased by other variables that are associated with both the marker and patient prognosis – in other words the comparison may be ‘confounded’.</p>
<p>Furthermore, while it may be of interest to know if a marker considered alone is prognostic, in most cases the real aim of a prognostic marker study should be to ascertain if the marker adds useful clinical information to what is already known. In many clinical contexts much is already known about prognosis, and it is important to know whether the new marker offers additional prognostic value over and above that achieved with previously identified prognostic variables. As an example, a study examined the ‘incremental usefulness’ of 10 biomarkers for predicting the risk of cardiovascular events, adjusted for age, sex, and conventional risk factors.130 That approach implies the addition of the marker to a statistical model that includes other known prognostic variables. As well as addressing the most sensible clinical question, adjustment should greatly reduce the risk of confounding.</p>
<p>Dealing with adjustment presents a problem for synthesis, as individual studies are likely to have used different statistical approaches for adjustment and adjusted for different selections of variables. Some syntheses avoid this methodological variation by using unadjusted estimates.131 While this approach is standard in systematic reviews of RCTs, in prognostic studies it replaces one problem with a worse one; unadjusted analyses are likely to be biased. Although the unadjusted estimate provides the maximum opportunity for comparison of consistent estimates across studies,131 it is important to adjust for other prognostic variables to get a valid picture of the relative prognosis for different values of the marker. Prognostic studies thus generally require analysis using multiple regression analysis, although stratification may be useful in simpler situations. For outcomes which are dichotomous or time to a specific event, logistic or Cox proportional hazards regression models respectively are appropriate for examining the influence of several prognostic factors simultaneously. For this purpose, known prognostic factors should preferably not be subjected to a variable selection process. Even though such variables may not reach specified levels of significance in a particular study, they should be included in the models generated in order to compare results to other reported studies. Comparison of models with and without the marker of interest provides an estimate of its independent effect and a test of statistical significance of whether the new marker contains additional prognostic information.</p>
<p>In practice, researchers will often find a mixture of adjusted and unadjusted results. Only 47/129 (36%) of prognostic marker studies in cancer used multivariate modelling in which the marker was added to standard clinical variables.132 A recent review presented separate meta-analyses of adjusted and unadjusted results of BCL-2 as a protective prognostic marker in breast cancer.133 It demonstrated, as expected, that the adjusted hazard ratio was lower than the unadjusted value but these differences were small (disease free survival (DFS) HR 1.58 vs HR 1.66). This approach reduces the need for speculation about the value of adjustment, which seems a good strategy even if all studies are then combined.</p>
</section>
<section id="sensitivity-analyses" class="level4" data-number="3.2.6.3">
<h4 data-number="3.2.6.3" class="anchored" data-anchor-id="sensitivity-analyses"><span class="header-section-number">3.2.6.3</span> Sensitivity analyses</h4>
<p>General considerations of investigating the sensitivity of the review findings to various choices apply equally to reviews of prognostic studies. In the specific context of prognosis, given the evidence about publication bias, it may be advisable to conduct a sensitivity analysis in which smaller studies are excluded.</p>
</section>
<section id="case-study" class="level4" data-number="3.2.6.4">
<h4 data-number="3.2.6.4" class="anchored" data-anchor-id="case-study"><span class="header-section-number">3.2.6.4</span> Case study</h4>
<p>An example of a systematic review addressing a prognostic question.</p>
<p>Objective</p>
<p>This systematic review of aggregate data obtained from study publications aimed to obtain better quantification of the prognostic importance of Ki-67/MIB- 1 expression as a marker of cell proliferation in early breast cancer. Ki-67 is present in all proliferating cells and there is great interest in its role as a marker of proliferation. MIB-1 is a monoclonal antibody against recombinant parts of the Ki-67 antigen.</p>
<p>Inclusion criteria</p>
<p>The review included studies evaluating the relationship between Ki-67/MIB-1 status and prognosis in early breast cancer published by May 2006. Studies had to have been published as a full paper in English. No minimal sample size or minimal median duration of follow-up was defined.</p>
<p>Searching</p>
<p>PubMed was searched using the following keywords: ‘breast cancer’, ‘Ki-67’, ‘MIB-1’, ‘proliferative index’, ‘proliferative marker’, ‘survival’ and ‘prognostic’. The authors also screened references from the relevant literature, including all the</p>
<p>identified studies and reviews. When the same patient population was reported in more than one publication, only the most recent or complete study was included.</p>
<p>Data extraction</p>
<p>The methods of Parmar et al134 were used to extract log HR and SE(log HR). Three people independently extracted information from survival curves.</p>
<p>Data availability</p>
<p>Sixty-eight eligible studies were identified of which 46 studies (including 12,155 patients) could be included in meta-analyses; 38 studies for disease free survival and 35 studies for overall survival.</p>
<p>Study characteristics</p>
<p>Table 2.5 shows that there was considerable variation in study characteristics, for example in patient characteristics, cutpoint used to define high Ki-67, and prevalence of raised levels of the marker. All studies dichotomised Ki-67 values. Even studies with the same threshold had prevalence of high values ranging from 11% to 88%. The studies also varied considerably in the interventions patients had received and in the antibody used in laboratory evaluations of Ki-67.</p>
<p>Systematic review of Ki-67 as a prognostic marker in early breast cancer: excerpt from table of study characteristics and results for disease-free survival (hazard ratios and 95% confidence intervals) 87</p>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 8%">
<col style="width: 19%">
<col style="width: 8%">
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 6%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Study</th>
<th style="text-align: left;">N</th>
<th style="text-align: left;">Follow- up (median months)</th>
<th style="text-align: left;">Threshold</th>
<th style="text-align: left;">Prevalence</th>
<th style="text-align: left;">How chosen</th>
<th style="text-align: left;">HR</th>
<th style="text-align: left;">95% CI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Bevilacqua, 1996</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>107</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>74</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>88%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>arbitrary</p>
</blockquote></td>
<td style="text-align: left;">2.75</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.02</p>
<p>7.39</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Bos, 2003</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>150</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>106</p>
<p>(mean)</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>42%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>arbitrary</p>
</blockquote></td>
<td style="text-align: left;">2.47</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.08</p>
<p>5.65</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Brown, 1996</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>674</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>72</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>5%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>25%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>optimal cutoff</p>
</blockquote></td>
<td style="text-align: left;">1.19</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>0.79</p>
<p>1.80</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Caly, 2004</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>244</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>72</p>
<p>(min)</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>32%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>50%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>unclear</p>
</blockquote></td>
<td style="text-align: left;">1.95</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>0.92</p>
<p>4.14</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Domagala (N0), 1996</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>111</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>88</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>60%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>median</p>
</blockquote></td>
<td style="text-align: left;">3.04</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.03</p>
<p>8.99</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Domagala (N+), 1996</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>75</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>88</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>53%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>median</p>
</blockquote></td>
<td style="text-align: left;">1.38</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>0.66</p>
<p>2.86</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Erdem, 2005</td>
<td style="text-align: left;">47</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>73</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>28%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>median</p>
</blockquote></td>
<td style="text-align: left;">17.23</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>2.42</p>
<p>122.4</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Fresno, 1997</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>146</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>75</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>58%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>arbitrary</p>
</blockquote></td>
<td style="text-align: left;">1.81</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>0.71</p>
<p>4.59</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Gasparini, 1994</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>165</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>60</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>7.5%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>50%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>mean</p>
</blockquote></td>
<td style="text-align: left;">2.58</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.21</p>
<p>5.49</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Gonzalez, 2003</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>221</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>103</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>30%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>NR</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>arbitrary</p>
</blockquote></td>
<td style="text-align: left;">3.18</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.52</p>
<p>6.65</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Goodson, 2000</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>112</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>61</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>24%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>50%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>mean</p>
</blockquote></td>
<td style="text-align: left;">2.90</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.18</p>
<p>7.15</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Heatley, 2002</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>59</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>60</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>44%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>mean</p>
</blockquote></td>
<td style="text-align: left;">0.81</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>0.36</p>
<p>1.81</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Hlupic (N+), 2004</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>192</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>180</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>61%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>arbitrary</p>
</blockquote></td>
<td style="text-align: left;">1.30</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>0.80</p>
<p>2.11</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Jacquemier, 1998</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>152</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>60</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>3.5%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>49%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>median</p>
</blockquote></td>
<td style="text-align: left;">3.29</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.49</p>
<p>7.22</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Jansen, 1998</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>321</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>128</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>7%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>48%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>median</p>
</blockquote></td>
<td style="text-align: left;">1.35</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.01</p>
<p>1.80</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Jensen, 1995</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>118</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>104</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>17%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>46%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>median</p>
</blockquote></td>
<td style="text-align: left;">3.41</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.44</p>
<p>8.06</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Liu, 2001</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>773</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>196</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>17.8%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>50%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>median</p>
</blockquote></td>
<td style="text-align: left;">1.76</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.41</p>
<p>2.20</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Locker, 1992</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>67</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>27</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>9%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>34%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>tertile</p>
</blockquote></td>
<td style="text-align: left;">4.19</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.19</p>
<p>14.7</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Mottolese, 2000</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>157</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>60</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>55%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>arbitrary</p>
</blockquote></td>
<td style="text-align: left;">1.82</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>0.90</p>
<p>3.67</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Pellikainen, 2003</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>414</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>57</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>20%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>44%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>arbitrary</p>
</blockquote></td>
<td style="text-align: left;">2.56</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.46</p>
<p>4.50</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Pierga, 1996</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>136</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>70</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>8%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>49%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>median</p>
</blockquote></td>
<td style="text-align: left;">1.37</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>0.64</p>
<p>2.91</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Pietilainen, 1996</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>188</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>103</p>
<p>(mean)</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>20%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>53%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>arbitrary</p>
</blockquote></td>
<td style="text-align: left;">1.88</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.16</p>
<p>3.05</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Pinder, 1995</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>177</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>NR</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>34%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>42%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>tertile</p>
</blockquote></td>
<td style="text-align: left;">1.66</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.09</p>
<p>2.52</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Pinto, 2001</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>295</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>39.6</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>46%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>arbitrary</p>
</blockquote></td>
<td style="text-align: left;">1.46</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>0.74</p>
<p>2.87</p>
</blockquote></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Querzoli, 1996</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>170</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>66.5</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>13%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>25%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>tertile</p>
</blockquote></td>
<td style="text-align: left;">2.05</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>1.11</p>
<p>3.77</p>
</blockquote></td>
</tr>
<tr class="even">
<td style="text-align: left;">Railo, 1993</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>326</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>32.4</p>
<p>(mean)</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>10%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>11%</p>
</blockquote></td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>unclear</p>
</blockquote></td>
<td style="text-align: left;">2.39</td>
<td style="text-align: left;"><blockquote class="blockquote">
<p>0.77</p>
<p>7.38</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p>N: Number of participants; HR: Hazard ratio; CI: Confidence interval</p>
<p>Meta-analysis</p>
<p>Study results were combined using the Peto-Yusuf method. No studies were excluded because of methodological quality but some studies were excluded because suitable data were not available – those included studies which did not provide unadjusted results. Random-effects meta-analyses were used because there was considerable heterogeneity. Separate meta-analyses were performed for overall (OS) and DFS. Both showed a significant association between raised Ki-67 and worse survival: HR 1.93 (95% CI: 1.74 – 2.14) and 1.95 (1.70 – 2.24)</p>
<p>respectively. Table 2.5 shows the reported characteristics and the results (HR) for DFS for a subset of the studies.</p>
<p>The 17 omitted studies were included in a sensitivity analysis with no appreciable change to the findings. The authors did not consider possible publication bias.</p>
<p>Conclusions</p>
<p>The authors concluded that ‘Despite some limitations, this meta-analysis supports the prognostic role of Ki-67 in early breast cancer, by showing a significant association between its expression and the risk of recurrence and death in all populations considered and for both outcomes, DFS and OS.’ They also noted that the reporting of the individual studies was suboptimal and that they had assessed only the univariate prognostic value of Ki-67. They suggested that a prospective study to examine whether Ki-67 was of prognostic importance over and above known factors. Thus, in common with many reviewers of such studies, these authors did not feel that the existing literature was strong enough on which to base clinical decisions.</p>
</section>
</section>
<section id="systematic-review-as-a-driver-for-improved-study-quality" class="level3" data-number="3.2.7">
<h3 data-number="3.2.7" class="anchored" data-anchor-id="systematic-review-as-a-driver-for-improved-study-quality"><span class="header-section-number">3.2.7</span> Systematic review as a driver for improved study quality</h3>
<p>Systematic reviews can play a valuable role not just in summarising the findings of published studies but also in drawing attention to the poor and inconsistent methods used. Good systematic reviews are needed to highlight the weaknesses of the evidence base behind prognostic markers and to provide guidance on how better-quality studies can be carried out in the future. This is true of prognostic studies and it has been commented that ’one has to question why it is acceptable for tumor marker studies to be performed with less scientific rigor than studies of new pharmaceutical agents.</p>
<p>As an example, a review of 26 published systematic reviews of prognostic markers in cancer found common deficiencies in both conduct and reporting.109 Less than 75% of the systematic reviews stated clearly their aims and objectives, the literature search strategy, and the study eligibility criteria. Only 20% reported the final number of primary studies used. Less than 50% of the systematic reviews reported elements of primary study description and analysis, such as sampling methods, cancer stage, cutpoint, and numeric results including CIs and P-values. The exception was the sample size, which was reported in 73% of the systematic reviews. About half of the systematic reviews had carried out a meta-analysis. Of those, some did not include a forest plot or numerical summary with confidence intervals. Most had explored heterogeneity,</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./interventions.html" class="pagination-link" aria-label="Systematic reviews of healthcare interventions">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Systematic reviews of healthcare interventions</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./summary.html" class="pagination-link" aria-label="Summary">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Summary</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>